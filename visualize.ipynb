{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from exec_funcs import preprocess_dataset, bucketize_dataset, get_val_df, calculate_aggregates_baseline, calculate_aggregates_pim, sort_pim_aggs\n",
    "from vis_funcs import generate_pixel_data, find_and_display_aggs, get_group\n",
    "from operator import itemgetter\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# EDIT\n",
    "# Specify path of file containing dataset to visualize.\n",
    "# Below code assumes file is a csv, but code should work fine as long as dataset is read into a pandas dataframe.\n",
    "file_path = \"taxi_data_2019_joined.csv\"\n",
    "df = pl.read_csv(file_path, try_parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Optional) EDIT\n",
    "# Set to True if you want to print a few rows of the dataset.\n",
    "if True:\n",
    "\tdisplay(df)\n",
    "\n",
    "# (Optional) EDIT\n",
    "# Set to True if you want to view the column names of the dataset.\n",
    "# This is useful when you want to inspect which columns would be interesting to visualize.\n",
    "if True:\n",
    "\tdisplay(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDIT\n",
    "# Specify columns to inspect during visualization. \n",
    "# e.g. If you want to look at column A and column B during visualization, you would write\n",
    "# columns_to_inspect = [['A'], ['B']]\n",
    "# e.g. If you want to look at column A and column B during visualization, and use column C as a secondary\n",
    "# attribute when sorting column A, you would write\n",
    "# columns_to_inspect = [['A', 'C'], ['B']]\n",
    "columns_to_inspect = [['pickup_time'], ['trip_distance'], ['PUBorough', 'PUservice_zone', 'PULat', 'PUZone'], ['passenger_count'], ['tip_amount']]\n",
    "#columns_to_inspect = [[df.columns[i]] for i in range(8)]\n",
    "\n",
    "# Specify aggregation value columns with their respective data type\n",
    "val_columns_and_types = [(None, pl.Int32), ('passenger_count', pl.Int32), ('fare_amount', pl.Float32), ('trip_distance', pl.Float64)]\n",
    "\n",
    "# Preprocess dataset.\n",
    "df_preprocessed = preprocess_dataset(df, columns_to_inspect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get subset of preprocessed dataset. This is user defined.\n",
    "df_analyze = df_preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDIT\n",
    "# Number of buckets used for visualization.\n",
    "bucket_num = 128\n",
    "\n",
    "bucket_df = bucketize_dataset(df_analyze, bucket_num, columns_to_inspect, len(df))\n",
    "val_df = get_val_df(df_analyze, val_columns_and_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exec_method = 2\n",
    "threads = 20\n",
    "divide = 2\n",
    "\n",
    "vals = val_df.select(pl.nth(0))\n",
    "\n",
    "pim = False\n",
    "buffer_size = 327680\n",
    "dpu_num = 64\n",
    "async_mode = False\n",
    "simulator = False\n",
    "correctness_check = False\n",
    "\n",
    "\n",
    "if pim:\n",
    "\tagg_info, aggs = calculate_aggregates_pim(bucket_df, vals, bucket_num, buffer_size, dpu_num, async_mode, simulator, correctness_check)\n",
    "else:\n",
    "\tagg_info, aggs = calculate_aggregates_baseline(exec_method, bucket_df, vals, bucket_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_aggs = len(agg_info)\n",
    "aggs = aggs.reshape([num_aggs, bucket_num, bucket_num, bucket_num])\n",
    "\n",
    "col_names = []\n",
    "\n",
    "agg_info, aggs = sort_pim_aggs(aggs, agg_info)\n",
    "\n",
    "for agg in agg_info:\n",
    "\tcol_name = '+'.join(columns_to_inspect[agg[0]]) + \"-\" + '+'.join(columns_to_inspect[agg[1]]) + \"-\" + '+'.join(columns_to_inspect[agg[2]])\n",
    "\tcol_names.append(col_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "frames = 4\n",
    "buckets_per_frame = int(bucket_num / frames)\n",
    "for a in range(num_aggs):\n",
    "\tprint(col_names[a])\n",
    "\t#curr_agg = aggs[a * (bucket_num ** 3) : (a + 1) * (bucket_num ** 3)]\n",
    "\tcurr_agg = aggs[a]\n",
    "\tcurr_agg = curr_agg.reshape(bucket_num, bucket_num ** 2)\n",
    "\tfor f in range(frames):\n",
    "\t\tframe_agg = curr_agg[buckets_per_frame * f : buckets_per_frame * (f+1)]\n",
    "\t\tframe_agg = np.sum(frame_agg, axis = 0).reshape(bucket_num, bucket_num)\n",
    "\n",
    "\t\t# generate_heatmap_frame(frame_agg.reshape(bucket_num, bucket_num), bucket_num)\n",
    "\n",
    "\t\t# Reverse frame agg on axis 0 so that y axis is in increasing order\n",
    "\t\tframe_agg = frame_agg[::-1]\n",
    "\t\tppm = generate_pixel_data(frame_agg)\n",
    "\t\timg = Image.fromarray(ppm)\n",
    "\t\t#img.save('thumbnails/' + col_names[a] + '-frame' + str(f) + '.jpeg')\n",
    "\t\tdisplay(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, c in enumerate(columns_to_inspect):\n",
    "\tprint(str(i) + \" \" + str(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print individual aggregates\n",
    "x_col = 1\n",
    "y_col = 4\n",
    "z_col = 2\n",
    "\n",
    "frames = 4\n",
    "\n",
    "find_and_display_aggs([z_col, y_col, x_col], aggs, agg_info, frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put images in groups that share x and y axes\n",
    "info = []\n",
    "\n",
    "frames = 4\n",
    "mode = 2\n",
    "top_n_image = 8\n",
    "top_n_groups = 5\n",
    "\n",
    "for x in range(len(columns_to_inspect) - 1):\n",
    "  for y in range(x+1, len(columns_to_inspect)):\n",
    "    print(x, y)\n",
    "    group_ppms = []\n",
    "    group_scores = []\n",
    "    for z in range(len(columns_to_inspect)):\n",
    "      if z != x and z != y:\n",
    "        ppms, scores = get_group([z, y, x], aggs, agg_info, frames, mode)\n",
    "        group_ppms += ppms\n",
    "        group_scores += scores\n",
    "    info.append([x, y, group_ppms, group_scores, np.sum(group_scores)])\n",
    "\n",
    "info = sorted(info, key=itemgetter(4), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Present images according to score\n",
    "top_n_image = 10\n",
    "top_n_groups = 5\n",
    "\n",
    "g_index = 0\n",
    "for i in info:\n",
    "  print(g_index)\n",
    "  print('X: ' + '+'.join(columns_to_inspect[i[0]]))\n",
    "  print('Y: ' + '+'.join(columns_to_inspect[i[1]]))\n",
    "  sorted_imgs = sorted(zip(i[3], i[2]), reverse=True, key=lambda x : (x[0], np.sum(x[1])))\n",
    "  curr = 0\n",
    "  for s, ppm in sorted_imgs:\n",
    "    print(s)\n",
    "    img = Image.fromarray(ppm)\n",
    "    display(img)\n",
    "    curr += 1\n",
    "    if curr == top_n_image:\n",
    "      break\n",
    "  g_index += 1\n",
    "  if g_index == top_n_groups:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define subset of data to analyze for equidistance binning\n",
    "# e.g. do data cleaning\n",
    "col_name = \"pickup_time\"\n",
    "df_analyze = df.with_columns(\n",
    "    (pl.col(col_name).dt.hour().cast(pl.Int32) * 60 + pl.col(col_name).dt.minute()).alias(col_name)\n",
    ")\n",
    "df_analyze = df_analyze.filter((pl.col(\"trip_distance\") < 20) & (pl.col(\"trip_distance\") >= 0))\n",
    "df_analyze = df_analyze.filter((pl.col(\"tip_amount\") < 10) & (pl.col(\"tip_amount\") >= 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_inspect = [['pickup_time'], ['trip_distance'], ['PUBorough', 'PUservice_zone', 'PULong', 'PUZone'], ['passenger_count'], ['tip_amount']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "from exec_funcs import equidistance_bin\n",
    "bins = 128\n",
    "binned_df = equidistance_bin(df_analyze, columns_to_inspect, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "def calculate_aggregate_equidistance(binned_df, cols):\n",
    "\tagg_shapes = [binned_df[c].max() + 1 for c in cols]\n",
    "\taggs = np.zeros(agg_shapes, dtype=np.uint32)\n",
    "\tgroup_by_df = binned_df.group_by(cols).len()\n",
    "\tgroup_by_df_np = group_by_df.to_numpy()\n",
    "\tfor r in group_by_df_np:\n",
    "\t\taggs[r[0]][r[1]][r[2]] += r[3]\n",
    "\treturn aggs\n",
    "\n",
    "aggs = []\n",
    "agg_info = []\n",
    "col_num = len(binned_df.columns)\n",
    "for i in range(col_num - 2):\n",
    "\tfor j in range(i + 1, col_num - 1):\n",
    "\t\tfor k in range(j + 1, col_num):\n",
    "\t\t\tagg = calculate_aggregate_equidistance(binned_df, [binned_df.columns[i], binned_df.columns[j], binned_df.columns[k]])\n",
    "\t\t\taggs.append(agg)\n",
    "\t\t\tagg_info.append([i, j, k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, c in enumerate(columns_to_inspect):\n",
    "\tprint(str(i) + \" \" + str(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print individual aggregates\n",
    "x_col = 2\n",
    "y_col = 1\n",
    "z_col = 0\n",
    "\n",
    "frames = 4\n",
    "\n",
    "find_and_display_aggs([z_col, y_col, x_col], aggs, agg_info, frames)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d0466e4c8e3a5016b210d778424aa4c4769f431dac2f5b2d5a42b178d70988b3"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('bucket_env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
